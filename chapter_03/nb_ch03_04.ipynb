{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nb_ch03_04.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bXDt1QFarxhc"
      },
      "source": [
        "## Performing a single backpropagation step to updata the parameter values once\n",
        "\n",
        "**Goal:** In this notebook you will see how to use tensorflow to do a single update step based on stochastic gradient descent with one data point. You will do one forward pass and one backward pass and extract the gradients of intermediate terms in the computational graph. You use them for computing the gradients of the loss w.r.t. the parameters (slope and intercept) which are needed to do one updatestep.\n",
        "\n",
        "**Usage:** The idea of the notebook is that you try to understand the provided code by running it, checking the output and playing with it by slightly changing the code and rerunning it. \n",
        "\n",
        "**Dataset:** You work with a single datapoint of the systolic blood pressure and age data of 33 American women, which is generated in the upper part of the notebook . \n",
        "\n",
        "**Content:**\n",
        "\n",
        "* read book chapter 3.4.1 check how the provided code corresponds to the step by step computations in this chapter. \n",
        "\n",
        "* use the tensorflow library to set up the model \n",
        "    * define a computational graph containing all intermediate terms and local gradients \n",
        "    * do a single forward pass and compute all intermediate terms\n",
        "    * do a single backward pass and compute all local gradients and use them to compute the gradients of the loss w.r.t. the parameters via chain rule\n",
        "    * do a single update step of the parameter values\n",
        "    * verify that the computed values for the gradients and the updated parameter values correspond to the values in chapter 3.4.1.\n",
        "\n",
        "\n",
        "\n",
        "[open in colab](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_04.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT-WLoi3XUyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try: #If running in colab \n",
        "    import google.colab\n",
        "    IN_COLAB = True \n",
        "    %tensorflow_version 1.x\n",
        "except:\n",
        "    IN_COLAB = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0TuJoV0XVXm",
        "colab_type": "code",
        "outputId": "27dd0ac2-2452-4aa5-8052-c58aae28a756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "if (tf.__version__.startswith('2')): #Checking if tf 2.0 is installed\n",
        "    print('Please install tensorflow 1.x to run this notebook')\n",
        "print('Tensorflow version: ',tf.__version__, ' running in colab?: ', IN_COLAB)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  1.15.0  running in colab?:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZkDvlnMjJxRe",
        "outputId": "4434ca7a-4dd7-4f97-ac78-b0c8cc978deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "import tensorflow as tf\n",
        "print('TF Version:', tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF Version: 1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qIev26Cqa0VC"
      },
      "source": [
        "#### Blood Pressure data\n",
        "\n",
        "Here we read in the systolic blood pressure and the age of the 33 American women in our dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zACb9J35KP92",
        "colab": {}
      },
      "source": [
        "# Blood Pressure data\n",
        "x = [22, 41, 52, 23, 41, 54, 24, 46, 56, 27, 47, 57, 28, 48, 58,  9, \n",
        "     49, 59, 30, 49, 63, 32, 50, 67, 33, 51, 71, 35, 51, 77, 40, 51, 81]\n",
        "y = [131, 139, 128, 128, 171, 105, 116, 137, 145, 106, 111, 141, 114, \n",
        "     115, 153, 123, 133, 157, 117, 128, 155, 122, 183,\n",
        "     176,  99, 130, 172, 121, 133, 178, 147, 144, 217] \n",
        "x = np.asarray(x, np.float32) \n",
        "y = np.asarray(y, np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4PVZDLZA0J3M"
      },
      "source": [
        "###  Doing the back propagation by hand for the example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GyWoQpLmjD_a"
      },
      "source": [
        "In the next cell we take only one woman of the dataset, because we want to calculate the gradients with only one datapoint. The woman is 58 years old and has a sbp value of 153."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uigQYLMs0B6s",
        "outputId": "d5574001-3562-4310-95c3-ac2421781370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = x[14]\n",
        "y = y[14]\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "58.0\n",
            "153.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LLnZCN2wjYlL"
      },
      "source": [
        "Here we define the computational graph with all the intermediate values and gradients in between, because we need them to apply the the chain rule and do the backpropagation. (see figure 3.12 in the book)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q8thmhCF0fq9",
        "colab": {}
      },
      "source": [
        "# Defining the graph (construction phase)\n",
        "\n",
        "tf.reset_default_graph()                                   # “Wipe the blackboard”, construct a new graph\n",
        "a_  = tf.Variable(0.0, name='a_var')                       # Variables, with starting values, will be optimized later\n",
        "b_  = tf.Variable(139.0, name='b_var')                     # we name them so that they look nicer in the graph\n",
        "x_  = tf.constant(x, name='x_const')                       # Constants, these are fixed tensors holding the data values and cannot be changed by the optimization\n",
        "y_  = tf.constant(y, name='y_const')  \n",
        "\n",
        "\n",
        "# We now do it step by step so that we can calculate the intermediate values and gradients\n",
        "ax_ = a_* x_\n",
        "abx_ = ax_ + b_\n",
        "r_ = abx_ - y_\n",
        "s_ = tf.square(r_)\n",
        "mse_ = tf.reduce_mean(s_)                                 \n",
        "\n",
        "grad_mse_s_ = tf.gradients(mse_, [s_])                      # gradient of mse_ w.r.t s_\n",
        "grad_s_r_ = tf.gradients(s_, [r_])                          # gradient of s_ w.r.t r_\n",
        "grad_r_abx_ = tf.gradients(r_, [abx_])                      # gradient of r_ w.r.t abx_\n",
        "grad_abx_b_ = tf.gradients(abx_, [b_])                      # gradient of abx_ w.r.t b_\n",
        "grad_abx_ax_ = tf.gradients(abx_, [ax_])                    # gradient of abx_ w.r.t ax_\n",
        "grad_ax_a_ = tf.gradients(ax_, [a_])                        # gradient of ax_ w.r.t a_\n",
        "\n",
        "grads_mse_a_b_ = tf.gradients(mse_, [a_,b_])                # gradient of mse_ w.r.t a_ and b_ (what we actually want)\n",
        "\n",
        "\n",
        "writer = tf.summary.FileWriter(\"linreg/\", tf.get_default_graph())\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jsNG3naRgPrU"
      },
      "source": [
        "#### Simple forward pass\n",
        "\n",
        "Now, let's do a simple forward pass and print the resulting values for ax, abx, r, s, and the mse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5WPxq0WSxkx6",
        "outputId": "cd21586f-9c43-43a8-a91d-82ae167c823c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "with tf.Session() as sess: \n",
        "    vals = sess.run([ax_,abx_,r_,s_,mse_], {a_:0,b_:139}) # Letting the variables a=3 b=1 flow through the graph\n",
        "    for p in vals:\n",
        "      print(p)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "139.0\n",
            "-14.0\n",
            "196.0\n",
            "196.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tjnLQHR5gder"
      },
      "source": [
        "#### Extracting the gradients and the updated values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JoSIz0E73JnD",
        "colab": {}
      },
      "source": [
        "# We add an addtional operation to the graph optimizing the mse_\n",
        "train_op_ = tf.train.GradientDescentOptimizer(learning_rate=0.00002).minimize(mse_) \n",
        "with tf.Session() as sess: \n",
        "    sess.run(tf.global_variables_initializer()) #Doing the initialization on the concrete realization of the graph\n",
        "    for i in range(1):\n",
        "      _, grad_mse_s,grad_s_r, grad_r_abx_,grad_abx_b, grad_abx_ax, grad_ax_a,a,b = sess.run([train_op_, grad_mse_s_, grad_s_r_, grad_r_abx_, grad_abx_b_, grad_abx_ax_,grad_ax_a_,a_,b_])   #fetch all the gradients here \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "reQ0PK5rvNRN",
        "outputId": "e1e13285-d950-45ad-ad70-2042690de4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(grad_mse_s,grad_s_r,grad_r_abx_,grad_abx_b,grad_abx_ax,grad_ax_a)\n",
        "print(a,b)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0] [-28.0] [1.0] [1.0] [1.0] [58.0]\n",
            "0.032479998 139.00056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6H0Sl_CUqsE",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/tensorchiefs/dl_book/master/imgs/ch03_12.pdf.png\" width=\"800\" align=\"left\" />  \n",
        "Compare the results of tensorflow with the results form the book where we did the forward and the backward pass by hand. The forward pass in blue and the backward pass in red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "93MFxmaGumoy",
        "outputId": "a860461e-960e-49cf-91c5-2eded0fc8546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with tf.Session() as sess: \n",
        "    sess.run(tf.global_variables_initializer()) #Doing the initialization on the concrete realization of the graph\n",
        "    for i in range(1):\n",
        "      grads_mse_a_b = sess.run(grads_mse_a_b_)   #fetch the gradients of mse w.r.t a and b  \n",
        "print(grads_mse_a_b)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1624.0, -28.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-WWZE95oAvtD"
      },
      "source": [
        "#### Compute the gradient of the mse w.r.t to a via the chain rule "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tjLESXafnhQB",
        "outputId": "b44fa6c4-0e1f-4087-843e-dc1eec3fcddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#grad_mse_a \n",
        "print(grad_mse_s[0]*grad_s_r[0]*grad_r_abx_[0]*grad_abx_ax[0]*grad_ax_a[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1624.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AUuVUqLwmg8Q",
        "outputId": "05b01fed-ff78-4a3a-c88d-0914bd01e05f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#grad_mse_b \n",
        "print(grad_mse_s[0]*grad_s_r[0]*grad_r_abx_[0]*grad_abx_b[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-28.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Subdq2jOmYMp"
      },
      "source": [
        "#### Update Formula\n",
        "Verify that we get the same if we do the upate \"by hand\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yGa4Z599kwjx",
        "outputId": "59b6b39a-992d-44b9-e430-eb4016be1342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a0=0\n",
        "b0=139\n",
        "eta=0.00002\n",
        "print(a0-eta*grads_mse_a_b[0])\n",
        "print(b0-eta*grads_mse_a_b[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.03248\n",
            "139.00056\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}